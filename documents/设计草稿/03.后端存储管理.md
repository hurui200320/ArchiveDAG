<h1>后端存储管理（Ariteg）</h1>

[TOC]

## 简述

该模块提供对Proto数据和元数据的存储管理功能。

## Merkle DAG

Merkle DAG是本模块的核心技术。由其名字可知，其本质上就是一个有向无环图（DAG），Merkle则表示它不使用内存指针寻找结点，而是使用结点的哈希来寻找结点（基于内容寻址）。

### 结点（Proto对象）

Merkle DAG的结点在代码中实现为Proto对象，因为每个节点都是用Protocol Buffer来描述与储存，于是简称Proto对象。一共有四种Proto对象：

+ Blob：表示一块数据，即代表一个字节数组。
+ List：是Blob的清单，表示几块数据拼起来，即由清单中所列的Blob对象所代表的字节数组顺序拼接而成。由此可以通过划分不同的Blob，再由一个List连接起来表示一个大文件，并使用Blob进行块级复用。
+ Tree：是Blob、List和Tree的有名顺序清单（逻辑上不要求有序，但改变顺序会引发对象哈希的变化），表示一个树状结构，其清单中的每一项都有名字，可以表示形如文件夹的树状结构。
+ Commit：表示一次提交，其中含有三个链接（父提交、提交作者、被提交对象）和一些额外数据（提交的时间戳、针对本次提交的文字说明）。每一次提交都是对Blob、List或Tree对象的一次拍照，并将快照状态追加到一个历史序列中，类似针对Proto对象的Git系统。

再系统中描述其他Proto对象的对象称为链接，代码中实现为`AritegLink`，其中有三个字段：

+ 链接的名称（用在Tree和Commit中）
+ 目标对象的哈希（主哈希的Multihash的Base58编码）
+ 目标对象的类型

### 有向无环图

利用如上四种Proto对象和一个链接，可以实现文件的块级去重、树状组织以及版本管理。

假设一个完美的分块算法可以精确且低成本地找出不同文件中的最大相同块，并以此将不同的文件切割成块，每个数据块作为字节数组保存成一个Blob对象，则相同的块就可以被不同的文件共享。由于链接使用哈希来寻找对象，因此被共享的Blob对象是不可变的。通过将Blob对象组织成List即可表示不同的文件，此时这些文件已经经过了块级去重。

Tree对象使得树状管理成为可能，但由于链接使用哈希来寻找对象，而子对象的内容也有哈希决定，因此Tree表示的树状关系是不可变的，因此现代文件系统中的硬连接是无法实现的——当被链接的树被改变时，系统将产生新的树对象，而硬连接所使用的哈希不会跟着自动改变。为了弥补这个缺点，目录管理将自动维护最新的Tree对象的链接，以保证修改后的目录项指向最新的版本，而硬连接则使用受控分享目录项来代替。

版本管理功能则依赖Commit对象，每一个版本对应一个Commit，他们由父提交链接形成一个提交链，目录项中记录最新一次Commit对象的链接，通过回溯commit对象的父提交，可以遍历整个提交历史，从而定位每一个历史版本。

![img](file:///C:/Users/hurui/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

该图展示了Merkle DAG的一个实例。提交对象ccc111是对树ttt111的一次快照，无论后续用户如何修改ttt111，从过ccc111总能还原到当前这个ttt111。可以看到图中的Blob对象bbb222被复用，它既是ttt111的一个子项，又是ttt333的子项。

## Multihash

单一的哈希函数无论如何安全，只要其输入空间大于输出空间，根据抽屉原理，其一定会产生碰撞。对于使用哈希寻址的系统来说，哈希碰撞意味着不同的数据产生了相同的哈希，进而其中一份数据被另一份不同的数据代替。这种碰撞对于存储系统是灾难性的，例如两个Blob对象A和B产生了相同的哈希，则系统会认为他们是重复的，则后来的数据B将被认为是数据A的副本，并使用了A的链接代替，当后续需要调取数据B时，服务器将数据B的部分替换为数据A，此时文件就损坏了。

由于哈希碰撞是不可避免的，若每次上传时都逐字节对比上传数据和已知数据，会给硬盘带来很大的压力，并且用户需要将待上传的文件完整上传一次。出于实用性考虑，这里我引入了双重哈希，即上传时对一份数据同时计算两份哈希，虽然还是存在哈希碰撞的可能性，但通过选择主副哈希的算法，可以将碰撞的几率降到几乎不可能。上传时用户只需要在本地分块，并将数据块的主副哈希提交给服务器，服务器就会得出三种结果：服务器中不存在对应的主哈希，可以上传；服务器中存在主哈希，并且副哈希对比一直，不需要上传；服务器中存在主哈希，但副哈希对比不一致，当前数据在主哈希算法上发生了碰撞，上传被拒绝。

推荐选择主哈希尽可能安全，输出空间尽可能大，例如SHA3-512，从根本减小主哈希碰撞的几率。

推荐选择副哈希与主哈希一样安全，并且计算比副哈希快，并且计算原理与主哈希不同（很显然，主哈希选SHA3-512，副哈希选SHA3-256，这对于减少碰撞几率没有什么帮助，因为他们是一个家族的算法，使用了类似的计算流程，拥有类似的安全漏洞与威胁特性），例如Blake系列的算法，Blake2b-512或Blake3（尚未编入Multihash）。但不可为了计算快而牺牲安全性，例如选择过时的SHA1或MD5。

## 配置

该模块提供了如下自动配置：

```
archive-dag.ariteg:
  storage:
    type: local_file_system_only
    threadSize: 16
    queue-size: 1024
    filesystem:
      path: "./data/protos"
    s3:
      endpoint: http://172.16.71.101:80
      accessKey: ACCESS_KEY
      secretKey: SECRET_KEY
      region: us-west-2
      bucket-name: skyblond-develop-test
      upload-storage-class: intelligent_tiering
```

这里只针对存储提供了基于实例的设置，因为元数据方面的设置放到了Etcd中以保证全局统一。

其中存储方式一共有两种：

+ `local_file_system_only`：该模式只使用本地文件系统进行存储。
+ `local_with_s3_archive`：该模式使用S3存储，但以本地文件系统作为缓存。

线程数量和队列大小用于设置存储后端的线程池，当任务数量超出队列大小时，任务将由提交者执行，从异步变为同步。

文件系统的配置需要指定一个存储数据的根目录，目录不存在时会自动创建。

使用S3则需要配置S3服务器的终端URL和访问密钥，默认为null，此时AWS S3 SDK将使用AWS S3作为终端，并自动搜索访问密钥，仅当不为null时才覆盖默认设置，用来连接私有S3网关。区域、桶名称和上传的存储类为必填项。

在自动配置时还会从Etcd集群中自动获取如下两个配置：

+ `/archive_dag/config/ariteg/proto/primary_hash_type`：存储管理使用的主哈希类型
+ `/archive_dag/config/ariteg/proto/secondary_hash_type`：存储管理使用的副哈希类型

与SpringBoot的自动配置不同，Etcd中的配置要求其内容能够顺利被`Multihash.Type.valueOf(...)`解析。这两个配置仅在实例启动时向Etcd获取，随后不再随Etcd更新。即便可以通过重启实例的方式修改，但此时程序无法感知哈希函数变化，虽然不会引发数据丢失，但对于新上传的数据将无法去重，需要额外的重新计算已有数据的哈希，并根据新的哈希重建Merkle DAG（**暂不支持**）。

## Multihash工具类

为了便于使用Multihash，提供了如下接口：

```kotlin
interface MultihashProvider {
    fun getType(): Multihash.Type
    fun digest(byteArray: ByteArray): Multihash
    fun digest(inputStream: InputStream, bufferSize: Int = 4096): Multihash
}
```

目前使用了JVM提供的实现（SHA3系列），以及BouncyCastle的实现（Blake2b系列），支持的Multihash类型如下：

```
sha3_256
sha3_512
blake2b_256
blake2b_384
blake2b_512
blake2s_128
blake2s_256
```

## 内部服务

`AritegMetaService`提供了Proto的元数据管理功能，元数据被存储在数据库中。提供了基本的元数据操作，例如增删改查等。

`DistributedLockService`提供了Etcd锁的服务，将锁加在`/application/ariteg/lock/proto:primary`，其中`primary`是主哈希的Base58编码。使用Etcd锁是避免依赖数据库锁，由于Spring JPA的save具有二义性：当主键不存在时表现为insert，当主键存在时表现在update，因此需要依赖Etcd锁来弱化对于数据库的要求，理论上不追求性能的话，整个集群使用一个Excel存元数据也没有问题（由Etcd锁保证独占写）。

## 存储后端

目前提供了两个存储后端。

### 仅本地文件系统

所有文件存储使用Java的File对象进行操作，理论上不光是本地硬盘，也可以是网络iSCSI块设备等。

### 本地+S3

与本地系统一样，但上传时同时写入本地与S3，下载时优先检查本地，本地没有看S3，若S3有，则S3下载到本地进行缓存。对于本地的文件，程序不会自动管理，但可以依靠shell脚本和定时任务自动清理`atime`旧于一定天数的文件（`rm $(ls -t --time=atime | tail -n 10)`），程序在本地找不到文件时会自动从S3下载。这种模式相当于使用S3存储，但以本地文件作为缓存。

## 对外暴露的服务

### AritegService

该服务提供了Proto对象的上传（自动处理元数据）、下载等基础操作，还提供了通过主副哈希检查Proto是否存在或冲突。

